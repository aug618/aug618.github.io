{"title":"水果分类识别优化","uid":"a1a68e61fba08a00939dcebf3ef65f10","slug":"水果分类优化","date":"2024-09-22T02:40:45.060Z","updated":"2024-09-22T03:20:28.912Z","comments":true,"path":"api/articles/水果分类优化.json","keywords":null,"cover":"https://images.pexels.com/photos/68525/soap-colorful-color-fruit-68525.jpeg?cs=srgb&dl=pexels-pixabay-68525.jpg&fm=jpg","content":"<h1 id=\"任务二：水果分类识别优化\"><a href=\"#任务二：水果分类识别优化\" class=\"headerlink\" title=\"任务二：水果分类识别优化\"></a>任务二：水果分类识别优化</h1><div class=\"language-txt\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">txt</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #babed8\">首先回顾一下之前的大体实现思路：</span></span></code></pre></div><h2 id=\"先前整体思路流程\"><a href=\"#先前整体思路流程\" class=\"headerlink\" title=\"先前整体思路流程\"></a>先前整体思路流程</h2><ol>\n<li><p><strong>特征提取</strong>：从图像中提取两类特征（边界特征和纹理特征），用于描述水果的形状和表面纹理。</p>\n</li>\n<li><p><strong>数据处理</strong>：读取数据目录中的图像，提取特征并准备数据集。</p>\n</li>\n<li><p><strong>模型训练</strong>：使用提取的特征数据训练一个逻辑回归模型，并保存为一个模型文件以待调用。</p>\n</li>\n<li><p><strong>单个图像预测</strong>：使用训练好的模型对单个图像进行预测，并输出预测结果。</p>\n</li>\n</ol>\n<h2 id=\"1-优化角度一：增加一个对比度特征向量的提取\"><a href=\"#1-优化角度一：增加一个对比度特征向量的提取\" class=\"headerlink\" title=\"1.优化角度一：增加一个对比度特征向量的提取\"></a>1.优化角度一：增加一个<strong>对比度特征向量</strong>的提取</h2><ol>\n<li>随机在图像内取两个点作大小随机的矩阵，计算两矩阵的均值，若第一个矩阵的均值大就记为1，否则记为0.</li>\n<li>这样取n次构成一个n维的特征向量，生成对比度特征向量。</li>\n<li>此后提取其他图像的这样的对比度的特征向量，用和之前相同的取矩阵的位置方法。</li>\n</ol>\n<p>为了确保提取特征的一致性，我们需要在 <strong>第一次随机取矩阵</strong> 时记录下所选的矩阵位置和大小，之后无论是训练其他样本还是对新图像进行预测，都使用相同的矩阵位置和大小。这样能保证特征提取方式在整个数据集和测试阶段都是一致的。</p>\n<details class=\"custom-details\">\n<summary>点击这里查看对比度特征向量提取代码</summary>\n<p><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 对比度特征提取函数（记录并使用相同的矩阵位置）</span><br><span class=\"line\">def extract_contrast_features(image, n=10, positions=None, is_training=True):</span><br><span class=\"line\">    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">    h, w = gray.shape</span><br><span class=\"line\"></span><br><span class=\"line\">    contrast_features = []</span><br><span class=\"line\">    global matrix_positions</span><br><span class=\"line\"></span><br><span class=\"line\">    if is_training and positions is None:</span><br><span class=\"line\">        matrix_positions = []  # 初始化矩阵位置</span><br><span class=\"line\"></span><br><span class=\"line\">    for i in range(n):</span><br><span class=\"line\">        if is_training and positions is None:  # 训练时，生成矩阵并保存位置</span><br><span class=\"line\">            x1, y1 = random.randint(0, w - 1), random.randint(0, h - 1)</span><br><span class=\"line\">            x2, y2 = random.randint(0, w - 1), random.randint(0, h - 1)</span><br><span class=\"line\">            size = random.randint(1, min(w, h) // 5)  # 矩阵大小</span><br><span class=\"line\">            size1, size2 = size, size</span><br><span class=\"line\">            matrix_positions.append(((x1, y1, size1), (x2, y2, size2)))  # 保存位置信息</span><br><span class=\"line\">        elif positions and i &lt; len(positions):  # 确保矩阵位置足够，避免超出范围</span><br><span class=\"line\">            ((x1, y1, size1), (x2, y2, size2)) = positions[i]</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            raise IndexError(f&quot;矩阵位置不足，尝试访问第 &#123;i&#125; 个矩阵位置&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 确保矩阵大小在图像边界内</span><br><span class=\"line\">        size1 = min(size1, w - x1, h - y1)</span><br><span class=\"line\">        size2 = min(size2, w - x2, h - y2)</span><br><span class=\"line\"></span><br><span class=\"line\">        roi1 = gray[y1:y1 + size1, x1:x1 + size1]</span><br><span class=\"line\">        roi2 = gray[y2:y2 + size2, x2:x2 + size2]</span><br><span class=\"line\"></span><br><span class=\"line\">        mean1 = np.mean(roi1) if roi1.size &gt; 0 else 0</span><br><span class=\"line\">        mean2 = np.mean(roi2) if roi2.size &gt; 0 else 0</span><br><span class=\"line\"></span><br><span class=\"line\">        contrast_features.append(1 if mean1 &gt; mean2 else 0)</span><br><span class=\"line\"></span><br><span class=\"line\">    return np.array(contrast_features)</span><br></pre></td></tr></table></figure>\n\n</p>\n</details>\n<h2 id=\"2-优化角度二：使用-CNN-替代逻辑回归模型\"><a href=\"#2-优化角度二：使用-CNN-替代逻辑回归模型\" class=\"headerlink\" title=\"2.优化角度二：使用 CNN 替代逻辑回归模型\"></a>2.优化角度二：使用 CNN 替代逻辑回归模型</h2><p>在之前的实现中，使用了逻辑回归模型来处理从图像中提取的边界特征、纹理特征和对比度特征。这种方法在特定任务上可以取得一定的效果，但当数据规模增加或特征变得更加复杂时，逻辑回归的表达能力有限。</p>\n<p>为了更好地处理图像分类任务，我们可以采用<strong>卷积神经网络（CNN）</strong>，它能更高效地提取图像中的空间特征，并在分类任务中通常能表现出优异的效果。</p>\n<h3 id=\"2-1-为什么选择-CNN？\"><a href=\"#2-1-为什么选择-CNN？\" class=\"headerlink\" title=\"2.1.为什么选择 CNN？\"></a>2.1.为什么选择 CNN？</h3><ul>\n<li><strong>局部感受野</strong>：卷积神经网络通过卷积操作可以捕捉图像中的局部特征，如边缘、纹理等，而这些特征对图像分类非常重要。</li>\n<li><strong>参数共享</strong>：卷积核参数共享，减少了模型的参数量，相对于全连接层来说更高效。</li>\n<li><strong>空间不变性</strong>：卷积操作可以在图像不同位置捕捉到类似的模式，有助于处理不同位置的图像特征。</li>\n</ul>\n<h3 id=\"2-2-CNN-模型设计\"><a href=\"#2-2-CNN-模型设计\" class=\"headerlink\" title=\"2.2.CNN 模型设计\"></a>2.2.CNN 模型设计</h3><p>为了保持对比度、边界和纹理特征的使用，同时引入 CNN 模型，我们可以将提取的特征输入到 CNN 中，通过卷积层和池化层进一步提取高层次的特征，并通过全连接层输出最终的分类结果。</p>\n<h3 id=\"2-3-CNN-模型结构\"><a href=\"#2-3-CNN-模型结构\" class=\"headerlink\" title=\"2.3.CNN 模型结构\"></a>2.3.CNN 模型结构</h3><ol>\n<li>卷积层（Conv Layer）<ul>\n<li>使用多层卷积操作提取图像的局部特征。每一层卷积层提取的特征会随着层数的增加逐渐从低级特征（如边缘）变为高级特征（如复杂的形状）。</li>\n</ul>\n</li>\n<li>池化层（Pooling Layer）<ul>\n<li>池化层用于减少特征图的大小，同时保持重要的特征，通常使用最大池化（MaxPooling）。</li>\n</ul>\n</li>\n<li>全连接层（Fully Connected Layer）<ul>\n<li>将卷积和池化操作后的特征展平，并通过全连接层进行分类。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"2-4-模型实现\"><a href=\"#2-4-模型实现\" class=\"headerlink\" title=\"2.4.模型实现\"></a>2.4.模型实现</h3><p>在模型实现中，首先需要对数据进行预处理，将提取的特征转换为适合 CNN 的输入格式。接着，我们通过卷积层和池化层对图像进行处理，最后通过全连接层输出分类结果。</p>\n<details class=\"custom-details\">\n<summary>以下是 CNN 模型的结构和训练流程的实现：</summary>\n<p><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># CNN 模型定义</span><br><span class=\"line\">class CNNModel(nn.Module):</span><br><span class=\"line\">    def __init__(self, input_size):</span><br><span class=\"line\">        super(CNNModel, self).__init__()</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 定义卷积层</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 定义全连接层</span><br><span class=\"line\">        self.fc1 = nn.Linear(64 * 7 * 7, 128)</span><br><span class=\"line\">        self.fc2 = nn.Linear(128, 3)  # 对应3个类别</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 定义池化层</span><br><span class=\"line\">        self.pool = nn.MaxPool2d(2, 2)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        # 卷积层 + 激活函数 + 池化</span><br><span class=\"line\">        x = self.pool(torch.relu(self.conv1(x)))</span><br><span class=\"line\">        x = self.pool(torch.relu(self.conv2(x)))</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 展平层</span><br><span class=\"line\">        x = x.view(-1, 64 * 7 * 7)</span><br><span class=\"line\">        </span><br><span class=\"line\">        # 全连接层</span><br><span class=\"line\">        x = torch.relu(self.fc1(x))</span><br><span class=\"line\">        x = self.fc2(x)</span><br><span class=\"line\">        return x</span><br></pre></td></tr></table></figure>\n\n</p>\n</details>\n<h3 id=\"2-5-数据处理\"><a href=\"#2-5-数据处理\" class=\"headerlink\" title=\"2.5.数据处理\"></a>2.5.数据处理</h3><p>为了适应 CNN 的输入要求，我们需要将提取的特征调整为二维形式，并且添加一个通道维度。</p>\n<details class=\"custom-details\">\n<summary>数据的预处理如下所示：</summary>\n<p><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 调整数据为 2D 图像形式 (batch_size, channels, height, width)</span><br><span class=\"line\">X_train = X_train.reshape(-1, 1, 28, 28)</span><br><span class=\"line\">X_test = X_test.reshape(-1, 1, 28, 28)</span><br><span class=\"line\"></span><br><span class=\"line\"># 转换为 PyTorch 数据集</span><br><span class=\"line\">train_dataset = FruitDataset(X_train, y_train)</span><br><span class=\"line\">test_dataset = FruitDataset(X_test, y_test)</span><br><span class=\"line\"></span><br><span class=\"line\">train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)</span><br><span class=\"line\">test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)</span><br></pre></td></tr></table></figure>\n\n</p>\n</details>\n<h3 id=\"2-6-模型训练\"><a href=\"#2-6-模型训练\" class=\"headerlink\" title=\"2.6.模型训练\"></a>2.6.模型训练</h3><p>接下来，我们定义了模型的训练过程，包括损失函数和优化器的选择，使用交叉熵损失和 Adam 优化器：</p>\n<details class=\"custom-details\">\n<summary>模型训练代码</summary>\n<p><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建 CNN 模型</span><br><span class=\"line\">input_size = 28 * 28  # 输入图像大小 28x28</span><br><span class=\"line\">model = CNNModel(input_size)</span><br><span class=\"line\"></span><br><span class=\"line\"># 使用交叉熵损失</span><br><span class=\"line\">criterion = nn.CrossEntropyLoss()</span><br><span class=\"line\"></span><br><span class=\"line\"># 使用 Adam 优化器</span><br><span class=\"line\">optimizer = optim.Adam(model.parameters(), lr=0.001)</span><br><span class=\"line\"></span><br><span class=\"line\"># 训练模型</span><br><span class=\"line\">n_epochs = 10</span><br><span class=\"line\">for epoch in range(n_epochs):</span><br><span class=\"line\">    model.train()</span><br><span class=\"line\">    running_loss = 0.0</span><br><span class=\"line\">    for inputs, labels in train_loader:</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        outputs = model(inputs)</span><br><span class=\"line\">        loss = criterion(outputs, labels)</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">        running_loss += loss.item()</span><br><span class=\"line\">    print(f&quot;Epoch &#123;epoch + 1&#125;/&#123;n_epochs&#125;, Loss: &#123;running_loss / len(train_loader)&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># 保存模型</span><br><span class=\"line\">torch.save(model.state_dict(), &#x27;cnn_model.pth&#x27;)</span><br></pre></td></tr></table></figure>\n\n</p>\n</details>\n<h3 id=\"2-7-模型评估\"><a href=\"#2-7-模型评估\" class=\"headerlink\" title=\"2.7.模型评估\"></a>2.7.模型评估</h3><p>训练完成后，我们在测试集上对模型进行评估，通过计算准确率、精度、召回率等指标来衡量模型的性能：</p>\n<details class=\"custom-details\">\n<summary>模型评估代码</summary>\n<p><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 评估模型</span><br><span class=\"line\">model.eval()</span><br><span class=\"line\">y_true = []</span><br><span class=\"line\">y_pred = []</span><br><span class=\"line\">with torch.no_grad():</span><br><span class=\"line\">    for inputs, labels in test_loader:</span><br><span class=\"line\">        outputs = model(inputs)</span><br><span class=\"line\">        _, predicted = torch.max(outputs, 1)</span><br><span class=\"line\">        y_true.extend(labels.numpy())</span><br><span class=\"line\">        y_pred.extend(predicted.numpy())</span><br><span class=\"line\"></span><br><span class=\"line\"># 计算准确率、精度、召回率</span><br><span class=\"line\">accuracy = accuracy_score(y_true, y_pred)</span><br><span class=\"line\">precision = precision_score(y_true, y_pred, average=&#x27;weighted&#x27;)</span><br><span class=\"line\">recall = recall_score(y_true, y_pred, average=&#x27;weighted&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">print(f&quot;准确率: &#123;accuracy:.2f&#125;&quot;)</span><br><span class=\"line\">print(f&quot;精度: &#123;precision:.2f&#125;&quot;)</span><br><span class=\"line\">print(f&quot;召回率: &#123;recall:.2f&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\"># 输出完整的分类报告</span><br><span class=\"line\">print(&quot;\\n分类报告：&quot;)</span><br><span class=\"line\">print(classification_report(y_true, y_pred, target_names=[&#x27;苹果&#x27;, &#x27;香蕉&#x27;, &#x27;橙子&#x27;]))</span><br></pre></td></tr></table></figure>\n\n</p>\n</details>\n<p><img src=\"/images/%E4%BC%98%E5%8C%96%E5%90%8E%E7%9A%84%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C\" alt=\"image-20240922111737466\"></p>\n<p>这一次的优化，使得水果分类识别模型的泛化能力、识别能力更强。通过结合对比度特征的提取和 CNN 模型，我们能够更好地捕捉图像的细节特征，提升分类的准确性。</p>\n","feature":true,"text":"任务二：水果分类识别优化txt首先回顾一下之前的大体实现思路：先前整体思路流程 特征提取：从图像中提取两类特征（边界特征和纹理特征），用于描述水果的形状和表面纹...","permalink":"/post/水果分类优化","photos":[],"count_time":{"symbolsCount":"5.6k","symbolsTime":"5 mins."},"categories":[{"name":"深度学习","slug":"深度学习","count":1,"path":"api/categories/深度学习.json"}],"tags":[{"name":"CNN","slug":"CNN","count":1,"path":"api/tags/CNN.json"},{"name":"水果分类","slug":"水果分类","count":2,"path":"api/tags/水果分类.json"},{"name":"计算机视觉","slug":"计算机视觉","count":2,"path":"api/tags/计算机视觉.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E6%B0%B4%E6%9E%9C%E5%88%86%E7%B1%BB%E8%AF%86%E5%88%AB%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">任务二：水果分类识别优化</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%88%E5%89%8D%E6%95%B4%E4%BD%93%E6%80%9D%E8%B7%AF%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">先前整体思路流程</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E4%BC%98%E5%8C%96%E8%A7%92%E5%BA%A6%E4%B8%80%EF%BC%9A%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E5%AF%B9%E6%AF%94%E5%BA%A6%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E6%8F%90%E5%8F%96\"><span class=\"toc-text\">1.优化角度一：增加一个对比度特征向量的提取</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-%E4%BC%98%E5%8C%96%E8%A7%92%E5%BA%A6%E4%BA%8C%EF%BC%9A%E4%BD%BF%E7%94%A8-CNN-%E6%9B%BF%E4%BB%A3%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">2.优化角度二：使用 CNN 替代逻辑回归模型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-1-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9-CNN%EF%BC%9F\"><span class=\"toc-text\">2.1.为什么选择 CNN？</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-2-CNN-%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1\"><span class=\"toc-text\">2.2.CNN 模型设计</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-3-CNN-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">2.3.CNN 模型结构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-4-%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">2.4.模型实现</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-5-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86\"><span class=\"toc-text\">2.5.数据处理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-6-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">2.6.模型训练</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-7-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0\"><span class=\"toc-text\">2.7.模型评估</span></a></li></ol></li></ol></li></ol>","author":{"name":"神秘奇男子","slug":"blog-author","avatar":"https://i.ibb.co/b3C0QpT/584-2022101195826670.jpg","link":"/","description":"但凡我有一点办法，我都不至于一点办法没有","socials":{"github":"https://github.com/August618?tab=repositories","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/august121wsy","csdn":"https://blog.csdn.net/UPCAUG?spm=1011.2124.3001.5343","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili.svg","link":"https://space.bilibili.com/1931947622/favlist?fid=1765359122"},"Gitee":{"icon":"/svg/gitee.svg","link":"https://gitee.com/wu-shanyu-AUG"}}}},"mapped":true,"hidden":false,"prev_post":{"title":"基于超像素距离的图像显著性分析","uid":"b72467b04a5c6bcacc1ed01fbb7a6241","slug":"基于超像素距离的图像显著性分析","date":"2024-10-07T12:16:07.266Z","updated":"2024-11-04T12:25:11.788Z","comments":true,"path":"api/articles/基于超像素距离的图像显著性分析.json","keywords":null,"cover":"https://uipv4.zywvvd.com:33030/HexoFiles/vvd_file_mt/202207071510708.jpg","text":"任务三：基于超像素距离生成显著性图像​ 首先我先描述一下我的大体实现思路： 1.整体思路流程 超像素分割：使用SLIC算法对图像执行超像素分割，得到分割后的区域...","permalink":"/post/基于超像素距离的图像显著性分析","photos":[],"count_time":{"symbolsCount":"1k","symbolsTime":"1 mins."},"categories":[{"name":"计算机视觉","slug":"计算机视觉","count":3,"path":"api/categories/计算机视觉.json"}],"tags":[{"name":"超像素分割","slug":"超像素分割","count":2,"path":"api/tags/超像素分割.json"},{"name":"图像显著性","slug":"图像显著性","count":2,"path":"api/tags/图像显著性.json"}],"author":{"name":"神秘奇男子","slug":"blog-author","avatar":"https://i.ibb.co/b3C0QpT/584-2022101195826670.jpg","link":"/","description":"但凡我有一点办法，我都不至于一点办法没有","socials":{"github":"https://github.com/August618?tab=repositories","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/august121wsy","csdn":"https://blog.csdn.net/UPCAUG?spm=1011.2124.3001.5343","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili.svg","link":"https://space.bilibili.com/1931947622/favlist?fid=1765359122"},"Gitee":{"icon":"/svg/gitee.svg","link":"https://gitee.com/wu-shanyu-AUG"}}}},"feature":true},"next_post":{"title":"MybatisPlus入门","uid":"f50948573c1bc1468571d16f17cedea9","slug":"MybatisPlus","date":"2024-09-20T12:19:36.839Z","updated":"2024-09-20T12:51:52.808Z","comments":true,"path":"api/articles/MybatisPlus.json","keywords":null,"cover":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ_t6KLyzOoKv3ViOi4e1PeC6GGX3N1Mc13-A&s","text":"MybatisPlus入门,它的愿景是成为 MyBatis 最好的搭档，就像魂斗罗 中的 1P、2P，基友搭配，效率翻倍。...","permalink":"/post/MybatisPlus","photos":[],"count_time":{"symbolsCount":"46k","symbolsTime":"42 mins."},"categories":[{"name":"SpringCloud","slug":"SpringCloud","count":1,"path":"api/categories/SpringCloud.json"}],"tags":[{"name":"java后端","slug":"java后端","count":1,"path":"api/tags/java后端.json"},{"name":"MybatisPlus","slug":"MybatisPlus","count":1,"path":"api/tags/MybatisPlus.json"}],"author":{"name":"神秘奇男子","slug":"blog-author","avatar":"https://i.ibb.co/b3C0QpT/584-2022101195826670.jpg","link":"/","description":"但凡我有一点办法，我都不至于一点办法没有","socials":{"github":"https://github.com/August618?tab=repositories","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"https://www.zhihu.com/people/august121wsy","csdn":"https://blog.csdn.net/UPCAUG?spm=1011.2124.3001.5343","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili.svg","link":"https://space.bilibili.com/1931947622/favlist?fid=1765359122"},"Gitee":{"icon":"/svg/gitee.svg","link":"https://gitee.com/wu-shanyu-AUG"}}}},"feature":true}}